{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "import tensorly as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata=pd.read_csv('imputed_data.csv') #Data imputed_data.csv prepared at matlab (1552210,41) with foward-fill imputation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths=pd.read_csv('lengths.csv',header=None) # Individual Length of Stay (LOS) fo all 40336 patients from taining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-arranging imputed 1552210 hours of data in 40336 recods\n",
    "k=0;\n",
    "b=[]\n",
    "intr=lengths.iloc[:].values\n",
    "intr1=np.array(intr,dtype=None)\n",
    "x=range(0,40336)\n",
    "for n in x:\n",
    "    var=[]    \n",
    "    aa=intr1[n]\n",
    "    a2=aa[0]\n",
    "    var=pd.DataFrame(fdata.iloc[k:k+a2,:].values)\n",
    "    b.append(var)\n",
    "    k=k+a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmi(df, positive=True):\n",
    "    col_totals = df.sum(axis=0)\n",
    "    total = col_totals.sum()\n",
    "    row_totals = df.sum(axis=1)\n",
    "    expected = np.outer(row_totals, col_totals) / total\n",
    "    df = df / expected\n",
    "    # Silence distracting warnings about log(0):\n",
    "    with np.errstate(divide='ignore'):\n",
    "        df = np.log(df)\n",
    "    df[np.isinf(df)] = 0.0  # log(0) = 0\n",
    "    if positive:\n",
    "        df[df < 0] = 0.0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\tensorly\\backend\\core.py:779: RuntimeWarning: invalid value encountered in sqrt\n",
      "  S = np.where(np.abs(S) <= np.finfo(S.dtype).eps, 0, np.sqrt(S))\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\tensorly\\backend\\core.py:780: RuntimeWarning: invalid value encountered in less_equal\n",
      "  V = np.dot(matrix.T.conj(), U * np.where(np.abs(S) <= np.finfo(S.dtype).eps, 0, 1/S)[None, :])\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\tensorly\\backend\\core.py:780: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  V = np.dot(matrix.T.conj(), U * np.where(np.abs(S) <= np.finfo(S.dtype).eps, 0, 1/S)[None, :])\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\tensorly\\decomposition\\_tucker.py:124: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  rec_error = sqrt(abs(norm_tensor**2 - tl.norm(core, 2)**2)) / norm_tensor\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in log\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#compute correlation of every 6 hours of data for 24 covariates(excluding covariates with \n",
    "#more than 95 % of missing values(10 covariates) and 6 demographics)\n",
    "# This cell corresponds to 80% of training data ~32222 patient records equivalent tp 1241759 hours of length of stay \n",
    "#out of 40336 patients. So this forms the training data for first fold\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.cp_tensor import cp_to_tensor, CPTensor\n",
    "feat2D = np.zeros((120,1241759))\n",
    "varr=0\n",
    "for rec in range(32222):\n",
    "    A=b[rec]\n",
    "    A2=A.drop(columns =[7 ,8 ,13, 14 ,16, 20, 22, 26, 27, 32 ,34 ,35,36 ,37 ,38, 39 ])\n",
    "\n",
    "    k=6\n",
    "    u=len(A2)\n",
    "    feat=[]\n",
    "    for j in range(u-5):  # Start appending matrices from 6th hour\n",
    "        var1=[]\n",
    "        ppmi=[]\n",
    "        var1=A2.iloc[j:k,:]\n",
    "        ppmi=pmi(var1,positive=True)\n",
    "        ppmi.fillna(0, inplace=True)\n",
    "    \n",
    "        k=k+1\n",
    "        feat.append(ppmi)\n",
    "    \n",
    "    var2=feat[0]        #replicate the 6th frame (matrix) to first 5 frames\n",
    "    aa=[]\n",
    "    for k in range(5):\n",
    "        aa.append(var2)\n",
    "    \n",
    "    newfeat=aa+feat \n",
    "    unfld=[]\n",
    "    for ll in range(len(newfeat)):\n",
    "        v1=np.array(newfeat[ll])\n",
    "        v2=v1.reshape(144)           # 6x24 =144\n",
    "        unfld.append(v2)# shape is 54,144\n",
    "\n",
    "    npunfld=np.array(unfld).T #144,54\n",
    "    npunfld1=npunfld.reshape(6,24,len(newfeat))\n",
    "\n",
    "    #tensor formation\n",
    "    tensor = tl.tensor(npunfld1, dtype=tl.float64)\n",
    "    unfolded = tl.unfold(tensor, mode=0)\n",
    "    tl.fold(unfolded, mode=0, shape=tensor.shape)\n",
    "\n",
    "    # Apply Tucker decomposition\n",
    "    Tucker_tensor = tucker(tensor,[6,20,u]) # R1=6, R2=20, R3= length of stay.\n",
    "    coreT=Tucker_tensor[0]\n",
    "\n",
    "    fm=coreT.reshape(120,len(A2)) # reshape core for 120 features...!\n",
    "    feat2D[:,varr:varr+len(A2)]=fm\n",
    "    #print(rec)\n",
    "    varr=varr+len(A2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1241759, 120)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat2DT=feat2D.T\n",
    "feat2DT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "with h5py.File('pmi120_fold1Strain.hdf5', \"w\") as f:\n",
    "    dset = f.create_dataset(\"default\", data = feat2DT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "with h5py.File('pmi_fold1Strain.hdf5', \"r\") as f:\n",
    "    feat2DT = np.array(f['default'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in log\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#compute correlation of every 6 hours of data for 24 covariates(excluding covariates with \n",
    "#more than 95 % of missing values(10 covariates) and 6 demographics)\n",
    "# This cell corresponds to 20% of testing data ~remaining 8114 (40336-32222)  training patient records equivalent tp 310451 hours of length of stay \n",
    "#out of 40336 patients. So this forms the 20% testing data for first fold\n",
    "\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.cp_tensor import cp_to_tensor, CPTensor\n",
    "feat2Dtest = np.zeros((120,310451))\n",
    "varr=0\n",
    "for rec in range(32222,40336):\n",
    "    A=b[rec]\n",
    "    A2=A.drop(columns =[7 ,8 ,13, 14 ,16, 20, 22, 26, 27, 32 ,34 ,35,36 ,37 ,38, 39])\n",
    "\n",
    "    k=6\n",
    "    u=len(A2)\n",
    "    feat=[]\n",
    "    for j in range(u-5):  # Start appending matrices from 7th hour\n",
    "        var1=[]\n",
    "        ppmi=[]\n",
    "        var1=A2.iloc[j:k,:]\n",
    "        ppmi=pmi(var1,positive=True)\n",
    "        ppmi.fillna(0, inplace=True)\n",
    "    \n",
    "        k=k+1\n",
    "        feat.append(ppmi)\n",
    "        \n",
    "    var2=feat[0]        #replicate the 7th frame (matrix) to first 6 frames\n",
    "    aa=[]\n",
    "    for k in range(5):\n",
    "        aa.append(var2)\n",
    "    \n",
    "    newfeat=aa+feat \n",
    "    unfld=[]\n",
    "    for ll in range(len(newfeat)):\n",
    "        v1=np.array(newfeat[ll])\n",
    "        v2=v1.reshape(144)           # 24x24 =576\n",
    "        unfld.append(v2)# shape is 54,576\n",
    "\n",
    "    npunfld=np.array(unfld).T #576,54\n",
    "    npunfld1=npunfld.reshape(6,24,len(newfeat))\n",
    "\n",
    "    #tensor formation\n",
    "    tensor_test = tl.tensor(npunfld1, dtype=tl.float64)\n",
    "    unfolded = tl.unfold(tensor_test, mode=0)\n",
    "    tl.fold(unfolded, mode=0, shape=tensor_test.shape)\n",
    "\n",
    "    # Apply Tucker decomposition\n",
    "    Tucker_tensor_test = tucker(tensor_test,[6,20,u]) # R1=10, R2=10, R3= length of stay.\n",
    "    coreT_test=Tucker_tensor_test[0]\n",
    "\n",
    "    fm_test=coreT_test.reshape(120,len(A2)) # rehape core for 100 features...!\n",
    "    feat2Dtest[:,varr:varr+len(A2)]=fm_test\n",
    "    #print(rec)\n",
    "    varr=varr+len(A2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "with h5py.File('pmi120_fold1Stest.hdf5', \"w\") as f:\n",
    "    dset = f.create_dataset(\"default\", data = feat2Dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "with h5py.File('pmi120_fold1Stest.hdf5', \"r\") as f:\n",
    "    feat2Dtest = np.array(f['default'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepsis_data1 = pd.read_csv('labels_sir.csv')\n",
    "Y=sepsis_data1.values\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1241759, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata1=feat2DT\n",
    "traindata1.shape\n",
    "trainlabels=Y[0:1241759];\n",
    "trainlabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310451, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata1=feat2Dtest.T\n",
    "testdata1.shape\n",
    "testlabels=Y[1241759:1552210];\n",
    "testlabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>range1</th>\n",
       "      <th>range2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40331</th>\n",
       "      <td>1552034</td>\n",
       "      <td>1552081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40332</th>\n",
       "      <td>1552082</td>\n",
       "      <td>1552106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40333</th>\n",
       "      <td>1552107</td>\n",
       "      <td>1552155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40334</th>\n",
       "      <td>1552156</td>\n",
       "      <td>1552175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40335</th>\n",
       "      <td>1552176</td>\n",
       "      <td>1552210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40336 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        range1   range2\n",
       "0            1       54\n",
       "1           55       77\n",
       "2           78      125\n",
       "3          126      154\n",
       "4          155      202\n",
       "...        ...      ...\n",
       "40331  1552034  1552081\n",
       "40332  1552082  1552106\n",
       "40333  1552107  1552155\n",
       "40334  1552156  1552175\n",
       "40335  1552176  1552210\n",
       "\n",
       "[40336 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = pd.read_csv('range1.csv')\n",
    "dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     1,     37],\n",
       "       [    38,     83],\n",
       "       [    84,    134],\n",
       "       ...,\n",
       "       [310348, 310396],\n",
       "       [310397, 310416],\n",
       "       [310417, 310451]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#range_test=range(32223:end,:)-1241759;\n",
    "range_test=dummy.iloc[32222:40336,:].values\n",
    "range_test1=range_test-1241759\n",
    "range_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32222        37\n",
       "32223        83\n",
       "32224       134\n",
       "32225       142\n",
       "32226       150\n",
       "          ...  \n",
       "40331    310322\n",
       "40332    310347\n",
       "40333    310396\n",
       "40334    310416\n",
       "40335    310451\n",
       "Name: range2, Length: 8114, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#range_test=range(32223:end,:)-1241759;\n",
    "range_test=dummy[32222:40336]\n",
    "range_test1=range_test-1241759\n",
    "a=range_test1.iloc[:,1]\n",
    "a\n",
    "#range_test2=range_test1[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=[]\n",
    "x=range(0,8114)\n",
    "for n in x:\n",
    "      b.append(a[n+32222])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, os, os.path, sys, warnings\n",
    "\n",
    "def evaluate_sepsis_score(label_directory, prediction_directory,num_files):\n",
    "    # Set parameters.\n",
    "    dt_early   = -12\n",
    "    dt_optimal = -6\n",
    "    dt_late    = 3\n",
    "\n",
    "    max_u_tp = 1\n",
    "    min_u_fn = -2\n",
    "    u_fp     = -0.05\n",
    "    u_tn     = 0\n",
    "\n",
    "    \n",
    "    # Compute utility.\n",
    "    observed_utilities = np.zeros(num_files)\n",
    "    best_utilities     = np.zeros(num_files)\n",
    "    worst_utilities    = np.zeros(num_files)\n",
    "    inaction_utilities = np.zeros(num_files)\n",
    "\n",
    "    for k in range(num_files):\n",
    "        labels = cohort_labels[k]\n",
    "        num_rows          = len(labels)\n",
    "        observed_predictions = cohort_predictions[k]\n",
    "        best_predictions     = np.zeros(num_rows)\n",
    "        worst_predictions    = np.zeros(num_rows)\n",
    "        inaction_predictions = np.zeros(num_rows)\n",
    "\n",
    "        if np.any(labels):\n",
    "            t_sepsis = np.argmax(labels) - dt_optimal\n",
    "            best_predictions[max(0, t_sepsis + dt_early) : min(t_sepsis + dt_late + 1, num_rows)] = 1\n",
    "        worst_predictions = 1 - best_predictions\n",
    "\n",
    "        observed_utilities[k] = compute_prediction_utility(labels, observed_predictions, dt_early, dt_optimal, dt_late, max_u_tp, min_u_fn, u_fp, u_tn)\n",
    "        best_utilities[k]     = compute_prediction_utility(labels, best_predictions, dt_early, dt_optimal, dt_late, max_u_tp, min_u_fn, u_fp, u_tn)\n",
    "        worst_utilities[k]    = compute_prediction_utility(labels, worst_predictions, dt_early, dt_optimal, dt_late, max_u_tp, min_u_fn, u_fp, u_tn)\n",
    "        inaction_utilities[k] = compute_prediction_utility(labels, inaction_predictions, dt_early, dt_optimal, dt_late, max_u_tp, min_u_fn, u_fp, u_tn)\n",
    "\n",
    "    unnormalized_observed_utility = np.sum(observed_utilities)\n",
    "    unnormalized_best_utility     = np.sum(best_utilities)\n",
    "    unnormalized_worst_utility    = np.sum(worst_utilities)\n",
    "    unnormalized_inaction_utility = np.sum(inaction_utilities)\n",
    "\n",
    "    normalized_observed_utility = (unnormalized_observed_utility - unnormalized_inaction_utility) / (unnormalized_best_utility - unnormalized_inaction_utility)\n",
    "\n",
    "    return  normalized_observed_utility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_auc(labels, predictions, check_errors=True):\n",
    "    # Check inputs for errors.\n",
    "    if check_errors:\n",
    "        if len(predictions) != len(labels):\n",
    "            raise Exception('Numbers of predictions and labels must be the same.')\n",
    "\n",
    "        for label in labels:\n",
    "            if not label in (0, 1):\n",
    "                raise Exception('Labels must satisfy label == 0 or label == 1.')\n",
    "\n",
    "        for prediction in predictions:\n",
    "            if not 0 <= prediction <= 1:\n",
    "                warnings.warn('Predictions do not satisfy 0 <= prediction <= 1.')\n",
    "\n",
    "    # Find prediction thresholds.\n",
    "    thresholds = np.unique(predictions)[::-1]\n",
    "    if thresholds[0] != 1:\n",
    "        thresholds = np.insert(thresholds, 0, 1)\n",
    "    if thresholds[-1] == 0:\n",
    "        thresholds = thresholds[:-1]\n",
    "\n",
    "    n = len(labels)\n",
    "    m = len(thresholds)\n",
    "\n",
    "    # Populate contingency table across prediction thresholds.\n",
    "    tp = np.zeros(m)\n",
    "    fp = np.zeros(m)\n",
    "    fn = np.zeros(m)\n",
    "    tn = np.zeros(m)\n",
    "\n",
    "    # Find indices that sort the predicted probabilities from largest to\n",
    "    # smallest.\n",
    "    idx = np.argsort(predictions)[::-1]\n",
    "\n",
    "    i = 0\n",
    "    for j in range(m):\n",
    "        # Initialize contingency table for j-th prediction threshold.\n",
    "        if j == 0:\n",
    "            tp[j] = 0\n",
    "            fp[j] = 0\n",
    "            fn[j] = np.sum(labels)\n",
    "            tn[j] = n - fn[j]\n",
    "        else:\n",
    "            tp[j] = tp[j - 1]\n",
    "            fp[j] = fp[j - 1]\n",
    "            fn[j] = fn[j - 1]\n",
    "            tn[j] = tn[j - 1]\n",
    "\n",
    "        # Update contingency table for i-th largest predicted probability.\n",
    "        while i < n and predictions[idx[i]] >= thresholds[j]:\n",
    "            if labels[idx[i]]:\n",
    "                tp[j] += 1\n",
    "                fn[j] -= 1\n",
    "            else:\n",
    "                fp[j] += 1\n",
    "                tn[j] -= 1\n",
    "            i += 1\n",
    "\n",
    "    # Summarize contingency table.\n",
    "    tpr = np.zeros(m)\n",
    "    tnr = np.zeros(m)\n",
    "    ppv = np.zeros(m)\n",
    "    npv = np.zeros(m)\n",
    "\n",
    "    for j in range(m):\n",
    "        if tp[j] + fn[j]:\n",
    "            tpr[j] = tp[j] / (tp[j] + fn[j])\n",
    "        else:\n",
    "            tpr[j] = 1\n",
    "        if fp[j] + tn[j]:\n",
    "            tnr[j] = tn[j] / (fp[j] + tn[j])\n",
    "        else:\n",
    "            tnr[j] = 1\n",
    "        if tp[j] + fp[j]:\n",
    "            ppv[j] = tp[j] / (tp[j] + fp[j])\n",
    "        else:\n",
    "            ppv[j] = 1\n",
    "        if fn[j] + tn[j]:\n",
    "            npv[j] = tn[j] / (fn[j] + tn[j])\n",
    "        else:\n",
    "            npv[j] = 1\n",
    "\n",
    "    # Compute AUROC as the area under a piecewise linear function with TPR /\n",
    "    # sensitivity (x-axis) and TNR / specificity (y-axis) and AUPRC as the area\n",
    "    # under a piecewise constant with TPR / recall (x-axis) and PPV / precision\n",
    "    # (y-axis).\n",
    "    auroc = 0\n",
    "    auprc = 0\n",
    "    for j in range(m-1):\n",
    "        auroc += 0.5 * (tpr[j + 1] - tpr[j]) * (tnr[j + 1] + tnr[j])\n",
    "        auprc += (tpr[j + 1] - tpr[j]) * ppv[j + 1]\n",
    "\n",
    "    return auroc, auprc\n",
    "\n",
    "# The compute_accuracy_f_measure function computes the accuracy and F-measure\n",
    "# for a patient.\n",
    "#\n",
    "# Inputs:\n",
    "#   'labels' is a binary vector, where labels[i] == 0 if the patient is not\n",
    "#   labeled as septic at time i and labels[i] == 1 if the patient is labeled as\n",
    "#   septic at time i.\n",
    "#\n",
    "#   'predictions' is a binary vector, where predictions[i] == 0 if the patient\n",
    "#   is not predicted to be septic at time i and predictions[i] == 1 if the\n",
    "#   patient is predicted to be septic at time i.  Note that there must be a\n",
    "#   prediction for every label, i.e, len(labels) == len(predictions).\n",
    "#\n",
    "# Output:\n",
    "#   'accuracy' is a scalar that gives the accuracy of the predictions using its\n",
    "#   binarized predictions.\n",
    "#\n",
    "#   'f_measure' is a scalar that gives the F-measure of the predictions using its\n",
    "#   binarized predictions.\n",
    "#\n",
    "# Example:\n",
    "#   In [1]: labels = [0, 0, 0, 0, 1, 1]\n",
    "#   In [2]: predictions = [0, 0, 1, 1, 1, 1]\n",
    "#   In [3]: accuracy, f_measure = compute_accuracy_f_measure(labels, predictions)\n",
    "#   In [4]: accuracy\n",
    "#   Out[4]: 0.666666666667\n",
    "#   In [5]: f_measure\n",
    "#   Out[5]: 0.666666666667\n",
    "\n",
    "def compute_accuracy_f_measure(labels, predictions, check_errors=True):\n",
    "    # Check inputs for errors.\n",
    "    if check_errors:\n",
    "        if len(predictions) != len(labels):\n",
    "            raise Exception('Numbers of predictions and labels must be the same.')\n",
    "\n",
    "        for label in labels:\n",
    "            if not label in (0, 1):\n",
    "                raise Exception('Labels must satisfy label == 0 or label == 1.')\n",
    "\n",
    "        for prediction in predictions:\n",
    "            if not prediction in (0, 1):\n",
    "                raise Exception('Predictions must satisfy prediction == 0 or prediction == 1.')\n",
    "\n",
    "    # Populate contingency table.\n",
    "    n = len(labels)\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        if labels[i] and predictions[i]:\n",
    "            tp += 1\n",
    "        elif not labels[i] and predictions[i]:\n",
    "            fp += 1\n",
    "        elif labels[i] and not predictions[i]:\n",
    "            fn += 1\n",
    "        elif not labels[i] and not predictions[i]:\n",
    "            tn += 1\n",
    "\n",
    "    # Summarize contingency table.\n",
    "    if tp + fp + fn + tn:\n",
    "        accuracy = float(tp + tn) / float(tp + fp + fn + tn)\n",
    "    else:\n",
    "        accuracy = 1.0\n",
    "\n",
    "    if 2 * tp + fp + fn:\n",
    "        f_measure = float(2 * tp) / float(2 * tp + fp + fn)\n",
    "    else:\n",
    "        f_measure = 1.0\n",
    "\n",
    "    return accuracy, f_measure\n",
    "\n",
    "# The compute_prediction_utility function computes the total time-dependent\n",
    "# utility for a patient.\n",
    "#\n",
    "# Inputs:\n",
    "#   'labels' is a binary vector, where labels[i] == 0 if the patient is not\n",
    "#   labeled as septic at time i and labels[i] == 1 if the patient is labeled as\n",
    "#   septic at time i.\n",
    "#\n",
    "#   'predictions' is a binary vector, where predictions[i] == 0 if the patient\n",
    "#   is not predicted to be septic at time i and predictions[i] == 1 if the\n",
    "#   patient is predicted to be septic at time i.  Note that there must be a\n",
    "#   prediction for every label, i.e, len(labels) == len(predictions).\n",
    "#\n",
    "# Output:\n",
    "#   'utility' is a scalar that gives the total time-dependent utility of the\n",
    "#   algorithm using its binarized predictions.\n",
    "#\n",
    "# Example:\n",
    "#   In [1]: labels = [0, 0, 0, 0, 1, 1]\n",
    "#   In [2]: predictions = [0, 0, 1, 1, 1, 1]\n",
    "#   In [3]: utility = compute_prediction_utility(labels, predictions)\n",
    "#   In [4]: utility\n",
    "#   Out[4]: 3.388888888888889\n",
    "\n",
    "def compute_prediction_utility(labels, predictions, dt_early=-12, dt_optimal=-6, dt_late=3.0, max_u_tp=1, min_u_fn=-2, u_fp=-0.05, u_tn=0, check_errors=True):\n",
    "    # Check inputs for errors.\n",
    "    if check_errors:\n",
    "        if len(predictions) != len(labels):\n",
    "            raise Exception('Numbers of predictions and labels must be the same.')\n",
    "\n",
    "        for label in labels:\n",
    "            if not label in (0, 1):\n",
    "                raise Exception('Labels must satisfy label == 0 or label == 1.')\n",
    "\n",
    "        for prediction in predictions:\n",
    "            if not prediction in (0, 1):\n",
    "                raise Exception('Predictions must satisfy prediction == 0 or prediction == 1.')\n",
    "\n",
    "        if dt_early >= dt_optimal:\n",
    "            raise Exception('The earliest beneficial time for predictions must be before the optimal time.')\n",
    "\n",
    "        if dt_optimal >= dt_late:\n",
    "            raise Exception('The optimal time for predictions must be before the latest beneficial time.')\n",
    "\n",
    "    # Does the patient eventually have sepsis?\n",
    "    if np.any(labels):\n",
    "        is_septic = True\n",
    "        t_sepsis = np.argmax(labels) - dt_optimal\n",
    "    else:\n",
    "        is_septic = False\n",
    "        t_sepsis = float('inf')\n",
    "\n",
    "    n = len(labels)\n",
    "\n",
    "    # Define slopes and intercept points for utility functions of the form\n",
    "    # u = m * t + b.\n",
    "    m_1 = float(max_u_tp) / float(dt_optimal - dt_early)\n",
    "    b_1 = -m_1 * dt_early\n",
    "    m_2 = float(-max_u_tp) / float(dt_late - dt_optimal)\n",
    "    b_2 = -m_2 * dt_late\n",
    "    m_3 = float(min_u_fn) / float(dt_late - dt_optimal)\n",
    "    b_3 = -m_3 * dt_optimal\n",
    "\n",
    "    # Compare predicted and true conditions.\n",
    "    u = np.zeros(n)\n",
    "    for t in range(n):\n",
    "        if t <= t_sepsis + dt_late:\n",
    "            # TP\n",
    "            if is_septic and predictions[t]:\n",
    "                if t <= t_sepsis + dt_optimal:\n",
    "                    u[t] = max(m_1 * (t - t_sepsis) + b_1, u_fp)\n",
    "                elif t <= t_sepsis + dt_late:\n",
    "                    u[t] = m_2 * (t - t_sepsis) + b_2\n",
    "            # FP\n",
    "            elif not is_septic and predictions[t]:\n",
    "                u[t] = u_fp\n",
    "            # FN\n",
    "            elif is_septic and not predictions[t]:\n",
    "                if t <= t_sepsis + dt_optimal:\n",
    "                    u[t] = 0\n",
    "                elif t <= t_sepsis + dt_late:\n",
    "                    u[t] = m_3 * (t - t_sepsis) + b_3\n",
    "            # TN\n",
    "            elif not is_septic and not predictions[t]:\n",
    "                u[t] = u_tn\n",
    "\n",
    "    # Find total utility for patient.\n",
    "    return np.sum(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_labels        = []\n",
    "cohort_predictions   = []\n",
    "cohort_probabilities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "            #'max_features':  hp.choice('max_features',['sqrt','log2', 0.5,0.75]), \n",
    "            'num_leaves': (40, 100), \n",
    "            'reg_lambda': (0, 10),\n",
    "            'lambda_l1': (0, 5),\n",
    "            'lambda_l2': (5, 10),\n",
    "            'max_depth': (10,20),\n",
    "            'scale_pos_weight':(18,40),\n",
    "            'learning_rate':(0.05,0.2),\n",
    "            'min_data_in_leaf':(40,100),\n",
    "            'reg_alpha': (0, 10),\n",
    "            #'min_split_gain':(0.01,10)\n",
    "    \n",
    "            \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(num_leaves,\n",
    "             reg_lambda,\n",
    "             lambda_l1,\n",
    "             lambda_l2,\n",
    "             max_depth,\n",
    "             scale_pos_weight,\n",
    "             learning_rate,\n",
    "             min_data_in_leaf,\n",
    "             reg_alpha):\n",
    "             #min_split_gain):\n",
    "        num_leaves = int(num_leaves)\n",
    "        min_data_in_leaf = int(min_data_in_leaf)\n",
    "        max_depth = int(max_depth)\n",
    "        #n_estimators =int(n_estimators)\n",
    "        params = {\n",
    "           # 'max_features': space['max_features'],\n",
    "            'num_leaves':num_leaves,\n",
    "            'reg_lambda':reg_lambda,\n",
    "            'lambda_l1':lambda_l1,\n",
    "            'lambda_l2':lambda_l2,\n",
    "            'max_depth':max_depth,\n",
    "            'scale_pos_weight':scale_pos_weight,\n",
    "            'learning_rate':learning_rate,\n",
    "            'min_data_in_leaf': min_data_in_leaf,\n",
    "            'reg_alpha': reg_alpha\n",
    "            #'min_split_gain':min_split_gain\n",
    "             }\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(traindata1, trainlabels, test_size=0.2, random_state=42)\n",
    "        import lightgbm as lgb\n",
    "        clf = lgb.LGBMClassifier(n_estimators=100, is_unbalanced=True, **params)\n",
    "        clf.fit(traindata1, trainlabels)#,early_stopping_rounds=100, eval_metric=\"f1_score\",\n",
    "        #eval_set=[(traindata1, trainlabels), (testdata1, testlabels)])\n",
    "        pred_scores = clf.predict_proba(testdata1)\n",
    "        pred_scores2=pred_scores[:,1]\n",
    "        y_pred=clf.predict(testdata1)\n",
    "        n=0\n",
    "        m=0\n",
    "        for k in b:\n",
    "            cohort_labels.append(testlabels[m:k])\n",
    "            cohort_predictions.append(y_pred[m:k])\n",
    "            cohort_probabilities.append(pred_scores2[m:k])\n",
    "            m=b[n]\n",
    "            n=n+1\n",
    "        \n",
    "        normalized_observed_utility = evaluate_sepsis_score(cohort_labels,cohort_predictions,len(cohort_labels));\n",
    "        return normalized_observed_utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lambda_l1', 'lambda_l2', 'learning_rate', 'max_depth', 'min_data_in_leaf', 'num_leaves', 'reg_alpha', 'reg_lambda', 'scale_pos_weight']\n",
      "|   iter    |  target   | lambda_l1 | lambda_l2 | learni... | max_depth | min_da... | num_le... | reg_alpha | reg_la... | scale_... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.3822  \u001b[0m | \u001b[0m 0.8002  \u001b[0m | \u001b[0m 7.309   \u001b[0m | \u001b[0m 0.1053  \u001b[0m | \u001b[0m 12.21   \u001b[0m | \u001b[0m 70.03   \u001b[0m | \u001b[0m 88.79   \u001b[0m | \u001b[0m 3.985   \u001b[0m | \u001b[0m 6.818   \u001b[0m | \u001b[0m 36.45   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.3812  \u001b[0m | \u001b[0m 2.121   \u001b[0m | \u001b[0m 6.901   \u001b[0m | \u001b[0m 0.09321 \u001b[0m | \u001b[0m 17.51   \u001b[0m | \u001b[0m 60.65   \u001b[0m | \u001b[0m 42.99   \u001b[0m | \u001b[0m 6.346   \u001b[0m | \u001b[0m 8.793   \u001b[0m | \u001b[0m 28.5    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.383   \u001b[0m | \u001b[95m 3.375   \u001b[0m | \u001b[95m 7.466   \u001b[0m | \u001b[95m 0.134   \u001b[0m | \u001b[95m 15.8    \u001b[0m | \u001b[95m 50.7    \u001b[0m | \u001b[95m 87.99   \u001b[0m | \u001b[95m 3.01    \u001b[0m | \u001b[95m 4.099   \u001b[0m | \u001b[95m 33.11   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.3839  \u001b[0m | \u001b[95m 1.316   \u001b[0m | \u001b[95m 5.107   \u001b[0m | \u001b[95m 0.1499  \u001b[0m | \u001b[95m 18.17   \u001b[0m | \u001b[95m 61.84   \u001b[0m | \u001b[95m 71.05   \u001b[0m | \u001b[95m 8.577   \u001b[0m | \u001b[95m 1.997   \u001b[0m | \u001b[95m 30.94   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.3841  \u001b[0m | \u001b[95m 1.221   \u001b[0m | \u001b[95m 7.342   \u001b[0m | \u001b[95m 0.1054  \u001b[0m | \u001b[95m 14.48   \u001b[0m | \u001b[95m 45.64   \u001b[0m | \u001b[95m 61.62   \u001b[0m | \u001b[95m 2.773   \u001b[0m | \u001b[95m 5.99    \u001b[0m | \u001b[95m 26.44   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.383   \u001b[0m | \u001b[0m 2.408   \u001b[0m | \u001b[0m 5.475   \u001b[0m | \u001b[0m 0.1605  \u001b[0m | \u001b[0m 10.56   \u001b[0m | \u001b[0m 79.2    \u001b[0m | \u001b[0m 49.04   \u001b[0m | \u001b[0m 7.604   \u001b[0m | \u001b[0m 2.794   \u001b[0m | \u001b[0m 23.51   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.3834  \u001b[0m | \u001b[0m 4.549   \u001b[0m | \u001b[0m 7.267   \u001b[0m | \u001b[0m 0.1741  \u001b[0m | \u001b[0m 12.68   \u001b[0m | \u001b[0m 74.53   \u001b[0m | \u001b[0m 48.03   \u001b[0m | \u001b[0m 9.928   \u001b[0m | \u001b[0m 5.402   \u001b[0m | \u001b[0m 29.3    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.3828  \u001b[0m | \u001b[0m 3.529   \u001b[0m | \u001b[0m 6.575   \u001b[0m | \u001b[0m 0.1072  \u001b[0m | \u001b[0m 15.44   \u001b[0m | \u001b[0m 44.38   \u001b[0m | \u001b[0m 48.83   \u001b[0m | \u001b[0m 7.631   \u001b[0m | \u001b[0m 7.91    \u001b[0m | \u001b[0m 35.8    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.3834  \u001b[0m | \u001b[0m 3.964   \u001b[0m | \u001b[0m 6.73    \u001b[0m | \u001b[0m 0.1513  \u001b[0m | \u001b[0m 16.56   \u001b[0m | \u001b[0m 41.64   \u001b[0m | \u001b[0m 90.93   \u001b[0m | \u001b[0m 2.007   \u001b[0m | \u001b[0m 4.689   \u001b[0m | \u001b[0m 27.59   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.384   \u001b[0m | \u001b[0m 3.803   \u001b[0m | \u001b[0m 6.476   \u001b[0m | \u001b[0m 0.1545  \u001b[0m | \u001b[0m 15.88   \u001b[0m | \u001b[0m 61.29   \u001b[0m | \u001b[0m 97.42   \u001b[0m | \u001b[0m 6.853   \u001b[0m | \u001b[0m 3.726   \u001b[0m | \u001b[0m 29.52   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.3839  \u001b[0m | \u001b[0m 1.359   \u001b[0m | \u001b[0m 8.048   \u001b[0m | \u001b[0m 0.06426 \u001b[0m | \u001b[0m 15.78   \u001b[0m | \u001b[0m 84.07   \u001b[0m | \u001b[0m 43.8    \u001b[0m | \u001b[0m 1.984   \u001b[0m | \u001b[0m 9.837   \u001b[0m | \u001b[0m 21.48   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.385   \u001b[0m | \u001b[95m 0.1407  \u001b[0m | \u001b[95m 6.345   \u001b[0m | \u001b[95m 0.07461 \u001b[0m | \u001b[95m 17.21   \u001b[0m | \u001b[95m 77.33   \u001b[0m | \u001b[95m 93.8    \u001b[0m | \u001b[95m 0.6373  \u001b[0m | \u001b[95m 0.1177  \u001b[0m | \u001b[95m 23.9    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m 13      \u001b[0m | \u001b[95m 0.3852  \u001b[0m | \u001b[95m 0.5191  \u001b[0m | \u001b[95m 6.974   \u001b[0m | \u001b[95m 0.09286 \u001b[0m | \u001b[95m 10.67   \u001b[0m | \u001b[95m 54.11   \u001b[0m | \u001b[95m 85.98   \u001b[0m | \u001b[95m 9.764   \u001b[0m | \u001b[95m 7.795   \u001b[0m | \u001b[95m 29.63   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.3849  \u001b[0m | \u001b[0m 3.444   \u001b[0m | \u001b[0m 5.97    \u001b[0m | \u001b[0m 0.1208  \u001b[0m | \u001b[0m 19.15   \u001b[0m | \u001b[0m 77.3    \u001b[0m | \u001b[0m 47.26   \u001b[0m | \u001b[0m 7.634   \u001b[0m | \u001b[0m 0.9162  \u001b[0m | \u001b[0m 29.67   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.3849  \u001b[0m | \u001b[0m 1.614   \u001b[0m | \u001b[0m 9.291   \u001b[0m | \u001b[0m 0.1274  \u001b[0m | \u001b[0m 16.87   \u001b[0m | \u001b[0m 76.55   \u001b[0m | \u001b[0m 71.04   \u001b[0m | \u001b[0m 0.699   \u001b[0m | \u001b[0m 0.1596  \u001b[0m | \u001b[0m 25.82   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m 16      \u001b[0m | \u001b[95m 0.3856  \u001b[0m | \u001b[95m 0.544   \u001b[0m | \u001b[95m 9.989   \u001b[0m | \u001b[95m 0.0501  \u001b[0m | \u001b[95m 19.38   \u001b[0m | \u001b[95m 69.89   \u001b[0m | \u001b[95m 50.13   \u001b[0m | \u001b[95m 8.163   \u001b[0m | \u001b[95m 8.157   \u001b[0m | \u001b[95m 23.5    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.3854  \u001b[0m | \u001b[0m 0.7968  \u001b[0m | \u001b[0m 6.384   \u001b[0m | \u001b[0m 0.08969 \u001b[0m | \u001b[0m 14.05   \u001b[0m | \u001b[0m 98.73   \u001b[0m | \u001b[0m 99.82   \u001b[0m | \u001b[0m 2.062   \u001b[0m | \u001b[0m 0.1524  \u001b[0m | \u001b[0m 19.72   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.3847  \u001b[0m | \u001b[0m 4.045   \u001b[0m | \u001b[0m 8.039   \u001b[0m | \u001b[0m 0.08505 \u001b[0m | \u001b[0m 13.33   \u001b[0m | \u001b[0m 97.6    \u001b[0m | \u001b[0m 99.89   \u001b[0m | \u001b[0m 9.973   \u001b[0m | \u001b[0m 2.82    \u001b[0m | \u001b[0m 18.13   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.3839  \u001b[0m | \u001b[0m 0.07474 \u001b[0m | \u001b[0m 7.36    \u001b[0m | \u001b[0m 0.1287  \u001b[0m | \u001b[0m 18.73   \u001b[0m | \u001b[0m 98.75   \u001b[0m | \u001b[0m 98.15   \u001b[0m | \u001b[0m 4.973   \u001b[0m | \u001b[0m 0.4716  \u001b[0m | \u001b[0m 18.21   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.3835  \u001b[0m | \u001b[0m 4.202   \u001b[0m | \u001b[0m 9.084   \u001b[0m | \u001b[0m 0.1021  \u001b[0m | \u001b[0m 11.47   \u001b[0m | \u001b[0m 98.44   \u001b[0m | \u001b[0m 99.56   \u001b[0m | \u001b[0m 6.524   \u001b[0m | \u001b[0m 0.02413 \u001b[0m | \u001b[0m 39.67   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.3829  \u001b[0m | \u001b[0m 2.412   \u001b[0m | \u001b[0m 6.001   \u001b[0m | \u001b[0m 0.1456  \u001b[0m | \u001b[0m 18.37   \u001b[0m | \u001b[0m 99.11   \u001b[0m | \u001b[0m 97.48   \u001b[0m | \u001b[0m 3.817   \u001b[0m | \u001b[0m 5.575   \u001b[0m | \u001b[0m 18.28   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.3824  \u001b[0m | \u001b[0m 0.7521  \u001b[0m | \u001b[0m 6.244   \u001b[0m | \u001b[0m 0.08831 \u001b[0m | \u001b[0m 19.07   \u001b[0m | \u001b[0m 99.88   \u001b[0m | \u001b[0m 95.6    \u001b[0m | \u001b[0m 2.28    \u001b[0m | \u001b[0m 8.552   \u001b[0m | \u001b[0m 18.17   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (4.788883439492664, 7.601159645758594, 0.12313084723221925, 15.767635077368421, 41.27123732679114, 99.59247854086802, 9.279296392197832, 4.108833734811293, 18.770370193169903)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-150-1d1605b1e3a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mLGB_BO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ucb'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-149-f888e8346e7e>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(num_leaves, reg_lambda, lambda_l1, lambda_l2, max_depth, scale_pos_weight, learning_rate, min_data_in_leaf, reg_alpha)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_unbalanced\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraindata1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#,early_stopping_rounds=100, eval_metric=\"f1_score\",\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[1;31m#eval_set=[(traindata1, trainlabels), (testdata1, testlabels)])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mpred_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestdata1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    798\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m                                         callbacks=callbacks)\n\u001b[0m\u001b[0;32m    801\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    593\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1924\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1925\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1926\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1927\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1928\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "LGB_BO = BayesianOptimization(objective, space)\n",
    "print(LGB_BO.space.keys)\n",
    "import warnings\n",
    "init_points = 16\n",
    "n_iter = 16\n",
    "with warnings.catch_warnings():  \n",
    "    warnings.filterwarnings('ignore')    \n",
    "LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Naimahmed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', lambda_l1=0.544, lambda_l2=9.989,\n",
       "               learning_rate=0.0501, max_depth=20, min_child_samples=20,\n",
       "               min_child_weight=0.001, min_data_in_leaf=70, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=51, objective=None,\n",
       "               random_state=None, reg_alpha=8.163, reg_lambda=8.157,\n",
       "               scale_pos_weight=23.5, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "#model = XGBClassifier(learning_rate=0.01, n_estimators=100, subsample=0.8, max_depth=3,objective='binary:logistic', reg_alpha=0.3,colsample_bytree=0.4,gamma=10,scale_pos_weight= 20)\n",
    "#model.fit(traindata1, trainlabels)\n",
    "\n",
    "model = lgb.LGBMClassifier(lambda_l1= 0.544,lambda_l2= 9.989,learning_rate=  0.0501, max_depth =20,min_data_in_leaf=70,num_leaves=51,reg_alpha=8.163,reg_lambda= 8.157,scale_pos_weight=23.50)\n",
    "#model = lgb.LGBMClassifier(lambda_l1= .9903,lambda_l2= 5.875,learning_rate= 0.1533, max_depth =18,min_data_in_leaf=80,num_leaves=63,reg_alpha=4.901,reg_lambda= 6.606,scale_pos_weight=30.15)\n",
    "#model = lgb.LGBMClassifier(lambda_l1= .4877,lambda_l2= 5.515,learning_rate= 0.07757, max_depth =18,min_data_in_leaf=78,num_leaves=46,reg_alpha=1.487,reg_lambda= 1.321,scale_pos_weight=31.42)\n",
    "#model = lgb.LGBMClassifier(lambda_l1= .1011,lambda_l2= 7.293,learning_rate= 0.1431, max_depth =17,min_data_in_leaf=88,num_leaves=56,reg_alpha=9.379,reg_lambda= 9.152,scale_pos_weight=39.02)\n",
    "#model = lgb.LGBMClassifier(lambda_l1= 4.592,lambda_l2= 8.396,learning_rate= 0.1873, max_depth =16,min_data_in_leaf=59,num_leaves=44,reg_alpha=5.79,reg_lambda= 7.227,scale_pos_weight=25.67)\n",
    "#0.544    |  9.989    |  0.0501   |  19.38    |  69.89    |  50.13    |  8.163    |  8.157    |  23.5     |\n",
    "\n",
    "model.fit(traindata1, trainlabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91847463, 0.08152537],\n",
       "       [0.91827449, 0.08172551],\n",
       "       [0.9124994 , 0.0875006 ],\n",
       "       ...,\n",
       "       [0.54283264, 0.45716736],\n",
       "       [0.49447994, 0.50552006],\n",
       "       [0.43843539, 0.56156461]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_scores = model.predict_proba(testdata1)\n",
    "pred_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310451,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_scores2=pred_scores[:,1]\n",
    "pred_scores2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310451,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(testdata1)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_labels        = []\n",
    "cohort_predictions   = []\n",
    "cohort_probabilities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "m=0\n",
    "for k in b:\n",
    "    cohort_labels.append(testlabels[m:k])\n",
    "    cohort_predictions.append(y_pred[m:k])\n",
    "    cohort_probabilities.append(pred_scores2[m:k])\n",
    "    m=b[n]\n",
    "    n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41099113737075343"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_observed_utility = evaluate_sepsis_score(cohort_labels,cohort_predictions,len(cohort_labels));\n",
    "normalized_observed_utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8889583219251992, 0.1405170909272233)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy_f_measure(testlabels,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8593520937685855, 0.11719252148124677)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_auc(testlabels,pred_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
